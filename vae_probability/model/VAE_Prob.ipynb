{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:/Users/z004uyxr/Documents/CVAE-Siemens/vae_probability')\n",
    "\n",
    "from src.data_generator.sequence_with_categories import generate_data\n",
    "from src.vae_model.multi_categorical_vae import build_vae_submodels\n",
    "from src.vae_model.common_functions import build_vae_from_models #changed to from src.vae_model.multi_categorical_vae import tfk \n",
    "                                                                 #(from vae_model.multivariate_sequence_vae import tfk)\n",
    "\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: C:\\Users\\z004uyxr\\Documents\\CVAE-Siemens\\vae_probability\\model\\..\\input_data\\prepared_data_182627.csv\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequence_data(file='input_data/prepared_data_182627.csv'):\n",
    "    def read_data_from_csv(file):\n",
    "        df = pd.read_csv(file)\n",
    "        df['Sequences'] = df['Sequences'].apply(literal_eval)\n",
    "        return df\n",
    "    \n",
    "    # Get the directory of the current script\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in locals() else os.getcwd()\n",
    "    \n",
    "    # Create the full path to the CSV file\n",
    "    file_path = os.path.join(script_dir, '..', 'input_data', 'prepared_data_182627.csv')\n",
    "    print(\"File path:\", file_path)\n",
    "\n",
    "    # Load data from CSV file\n",
    "    df = read_data_from_csv(file_path)\n",
    "\n",
    "    # Extract sequences\n",
    "    sequences = np.array(df['Sequences'])\n",
    "\n",
    "    return sequences\n",
    "\n",
    "\n",
    "# Usage\n",
    "sequences = prepare_sequence_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: GPU device not found.\n"
     ]
    }
   ],
   "source": [
    "# Print GPU information\n",
    "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "    print('WARNING: GPU device not found.')\n",
    "else:\n",
    "    print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape and VAE parameters\n",
    "input_shape = (25, 66)\n",
    "encoded_size = 16\n",
    "base_depth = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior distribution\n",
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1),\n",
    "                        reinterpreted_batch_ndims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "lambda (None, 25, 66)\n",
      "lstm (None, 25, 64)\n",
      "lstm_1 (None, 25, 64)\n",
      "lstm_2 (None, 25, 64)\n",
      "lstm_3 (None, 25, 32)\n",
      "lstm_4 (None, 25, 32)\n",
      "lstm_5 (None, 25, 32)\n",
      "flatten (None, 800)\n",
      "dense (None, 152)\n",
      "multivariate_normal_tri_l ((None, 16), (None, 16))\n"
     ]
    }
   ],
   "source": [
    "encoder = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=(25, 66)),  # Adjust input shape based on your data\n",
    "    tfkl.Lambda(lambda x: tf.cast(x, tf.float32) - 0.5),\n",
    "    tfkl.LSTM(2 * base_depth, return_sequences=True),\n",
    "    tfkl.LSTM(2 * base_depth, return_sequences=True),\n",
    "    tfkl.LSTM(2 * base_depth, return_sequences=True),\n",
    "    tfkl.LSTM(base_depth, return_sequences=True),\n",
    "    tfkl.LSTM(base_depth, return_sequences=True),\n",
    "    tfkl.LSTM(base_depth, return_sequences=True),\n",
    "    tfkl.Flatten(),\n",
    "    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size),\n",
    "               activation=None),\n",
    "    tfpl.MultivariateNormalTriL(\n",
    "        encoded_size,\n",
    "        activity_regularizer=tfpl.KLDivergenceRegularizer(prior)),\n",
    "])\n",
    "\n",
    "# Print shapes of tensors\n",
    "for layer in encoder.layers:\n",
    "    print(layer.name, layer.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = input_shape[1]  # Number of categories, adjust based on your data\n",
    "k = input_shape[0]  # Number of mixture components, adjust based on your requirement\n",
    "\n",
    "# Decoder model with LSTMs and CategoricalMixtureOfOneHotCategorical\n",
    "decoder = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=[encoded_size]),\n",
    "    tfkl.Reshape([1, encoded_size]),\n",
    "    LSTM(2 * base_depth, return_sequences=True),\n",
    "    LSTM(2 * base_depth, return_sequences=True),\n",
    "    LSTM(2 * base_depth, return_sequences=True),\n",
    "    LSTM(base_depth, return_sequences=True),\n",
    "    LSTM(base_depth, return_sequences=True),\n",
    "    LSTM(base_depth, return_sequences=True),\n",
    "    tfkl.Flatten(),\n",
    "    tfkl.Dense(d*k, activation=None),\n",
    "    tfpl.CategoricalMixtureOfOneHotCategorical(d, k),  # Output layer with CategoricalMixtureOfOneHotCategorical\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_16 (Reshape)        (None, 1, 16)             0         \n",
      "                                                                 \n",
      " lstm_183 (LSTM)             (None, 1, 64)             20736     \n",
      "                                                                 \n",
      " lstm_184 (LSTM)             (None, 1, 64)             33024     \n",
      "                                                                 \n",
      " lstm_185 (LSTM)             (None, 1, 64)             33024     \n",
      "                                                                 \n",
      " lstm_186 (LSTM)             (None, 1, 32)             12416     \n",
      "                                                                 \n",
      " lstm_187 (LSTM)             (None, 1, 32)             8320      \n",
      "                                                                 \n",
      " lstm_188 (LSTM)             (None, 1, 32)             8320      \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1650)              54450     \n",
      "                                                                 \n",
      " categorical_mixture_of_one  ((None, None),            0         \n",
      " _hot_categorical_3 (Catego   (None, None))                      \n",
      " ricalMixtureOfOneHotCatego                                      \n",
      " rical)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 170290 (665.20 KB)\n",
      "Trainable params: 170290 (665.20 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VAE model\n",
    "np.array(sequences[0]) == tfk.Model(inputs=encoder.inputs, outputs=decoder(encoder.outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the VAE model\n",
    "negloglik = lambda x, rv_x: -rv_x.log_prob(x)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=negloglik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 66)\n"
     ]
    }
   ],
   "source": [
    "# Example from Seq Array\n",
    "print(np.array(sequences[0]).shape)\n",
    "\n",
    "# Example Data\n",
    "example = np.array(sequences[0])\n",
    "output = vae(np.array([example]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 66), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sequences to NumPy array\n",
    "sequences_array = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[146], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the VAE model with only sequences\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequences_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# Train the VAE model with only sequences\n",
    "history = vae.fit(sequences_array, sequences_array, epochs=15, batch_size=256, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[147], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot training loss and validation loss over epochs\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot training loss and validation loss over epochs\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[148], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Generate sequences\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m generated_sequences \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# Generate sequences\n",
    "generated_sequences = vae.predict(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly Generated Samples:\n",
      "[[[0.5000012 ]]\n",
      "\n",
      " [[0.5000057 ]]\n",
      "\n",
      " [[0.50000155]]\n",
      "\n",
      " [[0.50000155]]\n",
      "\n",
      " [[0.49999455]]\n",
      "\n",
      " [[0.4999967 ]]\n",
      "\n",
      " [[0.49999925]]\n",
      "\n",
      " [[0.5000085 ]]\n",
      "\n",
      " [[0.49999574]]\n",
      "\n",
      " [[0.49999544]]\n",
      "\n",
      " [[0.49999836]]\n",
      "\n",
      " [[0.49999976]]\n",
      "\n",
      " [[0.49999693]]\n",
      "\n",
      " [[0.49999753]]\n",
      "\n",
      " [[0.4999977 ]]\n",
      "\n",
      " [[0.49998787]]\n",
      "\n",
      " [[0.5000007 ]]\n",
      "\n",
      " [[0.5000026 ]]\n",
      "\n",
      " [[0.49999413]]\n",
      "\n",
      " [[0.49999943]]\n",
      "\n",
      " [[0.500002  ]]\n",
      "\n",
      " [[0.49999908]]\n",
      "\n",
      " [[0.50000143]]\n",
      "\n",
      " [[0.50000215]]\n",
      "\n",
      " [[0.49999997]]\n",
      "\n",
      " [[0.49999988]]\n",
      "\n",
      " [[0.50000596]]\n",
      "\n",
      " [[0.50000155]]\n",
      "\n",
      " [[0.49999717]]\n",
      "\n",
      " [[0.50000453]]\n",
      "\n",
      " [[0.49999723]]\n",
      "\n",
      " [[0.49999997]]\n",
      "\n",
      " [[0.49999556]]\n",
      "\n",
      " [[0.5000061 ]]\n",
      "\n",
      " [[0.5000032 ]]\n",
      "\n",
      " [[0.500004  ]]\n",
      "\n",
      " [[0.49999562]]\n",
      "\n",
      " [[0.50000215]]\n",
      "\n",
      " [[0.49999392]]\n",
      "\n",
      " [[0.49999782]]\n",
      "\n",
      " [[0.49999395]]\n",
      "\n",
      " [[0.50000054]]\n",
      "\n",
      " [[0.5000056 ]]\n",
      "\n",
      " [[0.49999577]]\n",
      "\n",
      " [[0.5000032 ]]\n",
      "\n",
      " [[0.49999285]]\n",
      "\n",
      " [[0.5000042 ]]\n",
      "\n",
      " [[0.50000167]]\n",
      "\n",
      " [[0.50000155]]\n",
      "\n",
      " [[0.50000083]]\n",
      "\n",
      " [[0.5000038 ]]\n",
      "\n",
      " [[0.50000143]]\n",
      "\n",
      " [[0.4999956 ]]\n",
      "\n",
      " [[0.50000226]]\n",
      "\n",
      " [[0.4999983 ]]\n",
      "\n",
      " [[0.49999782]]\n",
      "\n",
      " [[0.49999577]]\n",
      "\n",
      " [[0.5000026 ]]\n",
      "\n",
      " [[0.5000001 ]]\n",
      "\n",
      " [[0.4999985 ]]\n",
      "\n",
      " [[0.5000007 ]]\n",
      "\n",
      " [[0.50000095]]\n",
      "\n",
      " [[0.50000024]]\n",
      "\n",
      " [[0.49999693]]\n",
      "\n",
      " [[0.49999824]]\n",
      "\n",
      " [[0.5000032 ]]\n",
      "\n",
      " [[0.49999982]]\n",
      "\n",
      " [[0.49999288]]\n",
      "\n",
      " [[0.50000644]]\n",
      "\n",
      " [[0.49999568]]\n",
      "\n",
      " [[0.50000405]]\n",
      "\n",
      " [[0.5000056 ]]\n",
      "\n",
      " [[0.50000435]]\n",
      "\n",
      " [[0.5000051 ]]\n",
      "\n",
      " [[0.50000024]]\n",
      "\n",
      " [[0.500002  ]]\n",
      "\n",
      " [[0.500003  ]]\n",
      "\n",
      " [[0.50000125]]\n",
      "\n",
      " [[0.5000011 ]]\n",
      "\n",
      " [[0.4999965 ]]\n",
      "\n",
      " [[0.50000095]]\n",
      "\n",
      " [[0.49999478]]\n",
      "\n",
      " [[0.499998  ]]\n",
      "\n",
      " [[0.50000274]]\n",
      "\n",
      " [[0.50000465]]\n",
      "\n",
      " [[0.5000011 ]]\n",
      "\n",
      " [[0.49999705]]\n",
      "\n",
      " [[0.49999782]]\n",
      "\n",
      " [[0.49999806]]\n",
      "\n",
      " [[0.5000057 ]]\n",
      "\n",
      " [[0.4999966 ]]\n",
      "\n",
      " [[0.5000018 ]]\n",
      "\n",
      " [[0.49999902]]\n",
      "\n",
      " [[0.5000021 ]]\n",
      "\n",
      " [[0.5000027 ]]\n",
      "\n",
      " [[0.49999914]]\n",
      "\n",
      " [[0.49999157]]\n",
      "\n",
      " [[0.49999925]]\n",
      "\n",
      " [[0.4999943 ]]\n",
      "\n",
      " [[0.49999902]]\n",
      "\n",
      " [[0.49999815]]\n",
      "\n",
      " [[0.49999624]]\n",
      "\n",
      " [[0.5000038 ]]\n",
      "\n",
      " [[0.5000043 ]]\n",
      "\n",
      " [[0.49999997]]\n",
      "\n",
      " [[0.49999586]]\n",
      "\n",
      " [[0.49999604]]\n",
      "\n",
      " [[0.4999995 ]]\n",
      "\n",
      " [[0.50000083]]\n",
      "\n",
      " [[0.49999312]]\n",
      "\n",
      " [[0.4999995 ]]\n",
      "\n",
      " [[0.49999812]]\n",
      "\n",
      " [[0.49999556]]\n",
      "\n",
      " [[0.49999824]]\n",
      "\n",
      " [[0.5000002 ]]\n",
      "\n",
      " [[0.50000596]]\n",
      "\n",
      " [[0.5000011 ]]\n",
      "\n",
      " [[0.5000011 ]]\n",
      "\n",
      " [[0.49999806]]\n",
      "\n",
      " [[0.5000027 ]]\n",
      "\n",
      " [[0.5000006 ]]\n",
      "\n",
      " [[0.4999932 ]]\n",
      "\n",
      " [[0.49999312]]\n",
      "\n",
      " [[0.4999992 ]]\n",
      "\n",
      " [[0.50000393]]\n",
      "\n",
      " [[0.49999955]]\n",
      "\n",
      " [[0.5000067 ]]\n",
      "\n",
      " [[0.5000025 ]]\n",
      "\n",
      " [[0.50000095]]\n",
      "\n",
      " [[0.4999986 ]]\n",
      "\n",
      " [[0.50000834]]\n",
      "\n",
      " [[0.49999765]]\n",
      "\n",
      " [[0.49999556]]\n",
      "\n",
      " [[0.49999106]]\n",
      "\n",
      " [[0.49999776]]\n",
      "\n",
      " [[0.5000015 ]]\n",
      "\n",
      " [[0.5000018 ]]\n",
      "\n",
      " [[0.5000012 ]]\n",
      "\n",
      " [[0.49999747]]\n",
      "\n",
      " [[0.49999586]]\n",
      "\n",
      " [[0.5000043 ]]\n",
      "\n",
      " [[0.49999985]]\n",
      "\n",
      " [[0.4999971 ]]\n",
      "\n",
      " [[0.49999967]]\n",
      "\n",
      " [[0.49999765]]\n",
      "\n",
      " [[0.50000036]]\n",
      "\n",
      " [[0.50000525]]\n",
      "\n",
      " [[0.4999963 ]]\n",
      "\n",
      " [[0.49999997]]\n",
      "\n",
      " [[0.49999806]]\n",
      "\n",
      " [[0.49999455]]\n",
      "\n",
      " [[0.500003  ]]\n",
      "\n",
      " [[0.5000019 ]]\n",
      "\n",
      " [[0.49999633]]\n",
      "\n",
      " [[0.5000018 ]]\n",
      "\n",
      " [[0.5000037 ]]\n",
      "\n",
      " [[0.5000118 ]]\n",
      "\n",
      " [[0.49999863]]\n",
      "\n",
      " [[0.50000584]]\n",
      "\n",
      " [[0.49999508]]\n",
      "\n",
      " [[0.5000007 ]]\n",
      "\n",
      " [[0.49999216]]\n",
      "\n",
      " [[0.50000095]]\n",
      "\n",
      " [[0.5000013 ]]\n",
      "\n",
      " [[0.4999997 ]]\n",
      "\n",
      " [[0.50000024]]\n",
      "\n",
      " [[0.4999965 ]]\n",
      "\n",
      " [[0.49999857]]\n",
      "\n",
      " [[0.49999973]]\n",
      "\n",
      " [[0.50000536]]\n",
      "\n",
      " [[0.50000095]]\n",
      "\n",
      " [[0.49999574]]\n",
      "\n",
      " [[0.4999969 ]]\n",
      "\n",
      " [[0.5000026 ]]\n",
      "\n",
      " [[0.5000044 ]]\n",
      "\n",
      " [[0.5000012 ]]\n",
      "\n",
      " [[0.49999604]]\n",
      "\n",
      " [[0.49999782]]\n",
      "\n",
      " [[0.4999989 ]]\n",
      "\n",
      " [[0.49999878]]\n",
      "\n",
      " [[0.4999978 ]]\n",
      "\n",
      " [[0.50000036]]\n",
      "\n",
      " [[0.5000063 ]]\n",
      "\n",
      " [[0.49999717]]\n",
      "\n",
      " [[0.49998954]]\n",
      "\n",
      " [[0.5000075 ]]\n",
      "\n",
      " [[0.49999815]]\n",
      "\n",
      " [[0.49999174]]\n",
      "\n",
      " [[0.50000376]]\n",
      "\n",
      " [[0.49999973]]\n",
      "\n",
      " [[0.49999413]]\n",
      "\n",
      " [[0.50000143]]\n",
      "\n",
      " [[0.50000143]]\n",
      "\n",
      " [[0.49999866]]\n",
      "\n",
      " [[0.5000003 ]]\n",
      "\n",
      " [[0.49999538]]\n",
      "\n",
      " [[0.49999765]]\n",
      "\n",
      " [[0.50000226]]\n",
      "\n",
      " [[0.50000167]]\n",
      "\n",
      " [[0.49999842]]\n",
      "\n",
      " [[0.49999997]]\n",
      "\n",
      " [[0.4999995 ]]\n",
      "\n",
      " [[0.49999776]]\n",
      "\n",
      " [[0.49999925]]\n",
      "\n",
      " [[0.49999377]]\n",
      "\n",
      " [[0.49999845]]\n",
      "\n",
      " [[0.50000364]]\n",
      "\n",
      " [[0.49999833]]\n",
      "\n",
      " [[0.49999985]]\n",
      "\n",
      " [[0.5000031 ]]\n",
      "\n",
      " [[0.500006  ]]\n",
      "\n",
      " [[0.4999964 ]]\n",
      "\n",
      " [[0.49999624]]\n",
      "\n",
      " [[0.49999884]]\n",
      "\n",
      " [[0.5000069 ]]\n",
      "\n",
      " [[0.49999985]]\n",
      "\n",
      " [[0.50000095]]\n",
      "\n",
      " [[0.5000087 ]]\n",
      "\n",
      " [[0.4999999 ]]\n",
      "\n",
      " [[0.50000083]]\n",
      "\n",
      " [[0.5000011 ]]\n",
      "\n",
      " [[0.49999958]]\n",
      "\n",
      " [[0.50000054]]\n",
      "\n",
      " [[0.50000113]]\n",
      "\n",
      " [[0.49999812]]\n",
      "\n",
      " [[0.49999896]]\n",
      "\n",
      " [[0.49999645]]\n",
      "\n",
      " [[0.5000018 ]]\n",
      "\n",
      " [[0.4999979 ]]\n",
      "\n",
      " [[0.5000051 ]]\n",
      "\n",
      " [[0.50000215]]\n",
      "\n",
      " [[0.4999936 ]]\n",
      "\n",
      " [[0.4999964 ]]\n",
      "\n",
      " [[0.5000012 ]]\n",
      "\n",
      " [[0.5000051 ]]\n",
      "\n",
      " [[0.5000025 ]]\n",
      "\n",
      " [[0.5000006 ]]\n",
      "\n",
      " [[0.49999768]]\n",
      "\n",
      " [[0.49999526]]\n",
      "\n",
      " [[0.5000005 ]]\n",
      "\n",
      " [[0.5000012 ]]\n",
      "\n",
      " [[0.50000334]]\n",
      "\n",
      " [[0.50000656]]\n",
      "\n",
      " [[0.49999902]]\n",
      "\n",
      " [[0.4999986 ]]\n",
      "\n",
      " [[0.5000067 ]]\n",
      "\n",
      " [[0.500002  ]]\n",
      "\n",
      " [[0.49999154]]\n",
      "\n",
      " [[0.50000584]]\n",
      "\n",
      " [[0.50000256]]\n",
      "\n",
      " [[0.500003  ]]\n",
      "\n",
      " [[0.4999977 ]]\n",
      "\n",
      " [[0.4999993 ]]\n",
      "\n",
      " [[0.50000644]]\n",
      "\n",
      " [[0.50000226]]\n",
      "\n",
      " [[0.49999395]]\n",
      "\n",
      " [[0.4999949 ]]\n",
      "\n",
      " [[0.49999836]]\n",
      "\n",
      " [[0.50000274]]\n",
      "\n",
      " [[0.49999556]]\n",
      "\n",
      " [[0.5000025 ]]\n",
      "\n",
      " [[0.50000143]]\n",
      "\n",
      " [[0.50000226]]\n",
      "\n",
      " [[0.5000007 ]]\n",
      "\n",
      " [[0.4999978 ]]\n",
      "\n",
      " [[0.4999971 ]]\n",
      "\n",
      " [[0.50000066]]\n",
      "\n",
      " [[0.5000025 ]]\n",
      "\n",
      " [[0.49999928]]\n",
      "\n",
      " [[0.49999776]]\n",
      "\n",
      " [[0.500002  ]]\n",
      "\n",
      " [[0.5000025 ]]\n",
      "\n",
      " [[0.49998844]]\n",
      "\n",
      " [[0.50000405]]\n",
      "\n",
      " [[0.49999866]]\n",
      "\n",
      " [[0.4999933 ]]\n",
      "\n",
      " [[0.5000007 ]]\n",
      "\n",
      " [[0.50000226]]\n",
      "\n",
      " [[0.49999955]]\n",
      "\n",
      " [[0.49999636]]\n",
      "\n",
      " [[0.49999723]]\n",
      "\n",
      " [[0.50000584]]]\n"
     ]
    }
   ],
   "source": [
    "# Display the randomly generated samples\n",
    "print('Randomly Generated Samples:')\n",
    "# Adjust the display function based on the nature of the output\n",
    "# For text-based output, you can use print or other suitable methods\n",
    "print(generated_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
